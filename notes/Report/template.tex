\documentclass[a4paper,11pt]{report}
\usepackage{alltt, fancyvrb, url}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{enumitem}
%\usepackage{algorithmic}
\usepackage[utf8]{inputenc}
\usepackage{fontenc}
\usepackage{amsthm}
\usepackage[english]{babel}
%stmaryrd,algorithm
\usepackage{amsmath,mathtools}
\usepackage{amssymb}
% Remove option to use English naming
\usepackage[english]{cleveref}
\graphicspath{ {img/} }

\usepackage{amsmath}


\begin{document}
	
	\begin{titlepage}
		\begin{center}
			{{\large{\textsc{Alma Mater Studiorum $\cdot$ Universit\`a di
							Bologna\\Campus di Cesena}}}} \rule[0.2cm]{15.8cm}{0.2mm}
			\rule[0.5cm]{15.8cm}{0.6mm}
			{\small 			{{\bf SCIENCES AND ENGINEERING\\
						THREE-YEAR DEGREE COURSE IN COMPUTER SCIENCE AND ENGINEERING
			}}}
		\end{center}
		\vspace{5mm}
		\begin{center}
			%{\LARGE{\bf TITOLO DELL'ELABORATO}}\\
			%\vspace{5mm}
			{\LARGE{\bf Analysis and Implementation of Algorithms for Bicriteria Shortest Paths Problems}}\\
			\vspace{3mm}
		\end{center}
		\vspace{3mm}
		\begin{center}
			\large{Elaborato in\\
				RICERCA OPERATIVA}
		\end{center}
		\vspace{30mm}
		\par
		\noindent
		\begin{minipage}[t]{0.47\textwidth}
			{\large{\bf Relatore:\\Cha.mo Prof.\\
					VIGO DANIELE}}
		\end{minipage}
		\vspace{5mm}
		\begin{minipage}[t]{0.47\textwidth}\raggedleft
			{\large{\bf Presentata da:\\
					ROSSOLINI ANDREA}}
		\end{minipage}\\
		\begin{minipage}[t]{1.5\textwidth}\raggedright
			{\large{\bf Corelatore:\\
					N\'ERON EMMANUEL}}
		\end{minipage}
		\hfill
		\vspace{20mm}
		\begin{center}
			{\large{\bf Anno Accademico: 2018/2019\\III sessione di laurea}}%inserire l'anno accademico a cui si è iscritti
		\end{center}
	\end{titlepage}


\begin{abstract}
In this paper a \textit{pathfinding} problem is analyzed starting from a classical shortest path problem and then, after several optimization, going to resolve a graph that utilizes two static weights on its arcs, considering the most full satisfying set of solutions.

As well known, Dijkstra's algorithm is the most widely used to solve routing problems; in fact is very easy to create an implementation that attempts to find the best path in a classical weighted graph. So the paper will focus on the operations of optimization.
%
The main part of the paper is the one that analyzes the paths of a graph with two weights for each arc, one value represents the distance (also present in the mono-criteria problem) and the other represents the danger of that arc. So the implementation will not only find the shortest and safest path, but also all the paths (not dominated) that take intermediate values.
\end{abstract}

\tableofcontents

\chapter{Introduction}
Dijkstra's algorithm is widely used to find shortest path in routing problems that use graphs with not-negative and static values. But this algorithm takes into consideration only one ``dimension'' of costs; for example, to calculate a path from the source node to the destination, distance is the result of adding up the length between two nodes segment by segment.
%
But the problem faced in this study considers two criteria for choosing the wanted path: the first cost defines the distance, while the second one represents the danger. Simply applying Dijkstra's algorithm it is possible to found a path very short, but it might be very dangerous, or vice versa. Multicriteria shortest path problem aims to determine a path that optimizes the costs from a source to the target. In general, there is not a single optimal solution; the goal of this project is to determinate a set of feasible and not-dominated solutions, finding different paths based on two criteria, so not only minimizing either distance or danger, but the relations between this two values.
\vspace{5mm}

\begin{figure}[H]
	\centering
	\includegraphics[width=\linewidth]{img/exampleGraph1}
	\caption{Graph example.}
	\label{fig:graphExample}
\end{figure}

\begin{table}[h]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		$p1$ & $1\to2\to4\to6$ & (11, 25) \\ \hline
		$p2$ & $1\to2\to5\to6$ & (13, 11)  \\ \hline
		$p3$ & $1\to3\to5\to6$ & (21, 6)  \\ \hline
		$p4$ & $1\to3\to4\to6$ & (13, 18)  \\ \hline
	\end{tabular}
	\caption{Graph's solution}
	\label{tab:graphExample}
\end{table}

In fig.\ref{fig:graphExample} an example of a double criterion's routing is shown. The nodes are labeled with numbers $\{1,2, ..., 6\}$ and the weights of the arcs are represented as a pair of value (\textit{a, b}), where \textit{a} is distance and \textit{b} is danger.

In table \ref{tab:graphExample} all the possible graph's iterations are shown: $p1$ and $p3$, respectively the shortest and the safest paths, $p2$ is a not-dominated solution (it is longer than $p1$ but safer and more dangerous then $p3$, but shorter) and $p4$ is a dominated path (because it is longer and safer than $p1$, most dangerous and shorter than $p3$, but it has no advantage over $p2$ which has the same value of distance but is safer) so it is useless to us (for the formal definition see ch.3).


 
\section{Mathematical formulation}

Let $G(N,A)$ denotes direct network which is composed of a finite set $N=\{0,1, \dots, n\}$ of nodes and a finite set $A \subseteq N\times N $, that represents the set of directed edges. Each arc can be denoted as an ordered pair $(i,j)$, where $i\in N$, $j \in N$ and both are two different nodes in $G(N,A)$.\\
Let define $c^k_{i,j}$ where $(i,j)\in A$ and $1\leq k \leq 2$ (because it is a double criterion problem) represent the cost which referring to. Let's define two nodes in the graph: $s$ and $t$, where $s \in N$ and $t \in N$, these are respectively the \textit{source} and \textit{target} of which one or more paths are searched.
%dei quali noi vogliamo trovare uno o più percorsi
A path $p_{s,t}$ can be qualified as a sequence  of  alternating nodes and arcs: $p_{s,t} = \{s, (s, i_1), i_1, \dots, i_{l}, (i_l,t), t\}$.\\
So it is possible to say that each $c^k_{i,j}$ refers to one of the two costs of each arc $(i,j)$, therefore the total cost of the entire path can be represented in this way:\\

\begin{gather}(c^1(p_{s,t}), c^2(p_{s,t}))\end{gather}
\begin{gather}c^1(p_{s,t})=\sum_{(i,j)\in p}c^1_{i,j}\end{gather}
\begin{gather}c^2(p_{s,t})=\sum_{(i,j)\in p}c^2_{i,j}\end{gather}
Our purpose is to \textbf{minimize} the $(1.2)$ to find the shortest path or the $(1.3)$ to find the safest one.

\chapter{Mono-criteria algorithms}

In this chapter the algorithms which concern the single criteria routing will be explained.
The analysis focuses on the evolution and optimization of the Dijkstra's algorithm, explaining some implementation choices.

\section{Dijkstra's algorithms}

Dijkstra's algorithm is a very famous algorithm used to find the shortest paths between nodes in a graph connected by arcs with positive weights.\\
Different implementation of this algorithm are present in this paper. In the following a brief explanation of the implementations referred in this paper.

\begin{figure}
	%\begin{BVerbatim}
	\verb|function DijkstraAlgorithm(source, target):|\\
	\verb|	    dist[source]| $\leftarrow$ 0\\
	\verb|	    create priorityQueue Q|\\
	\verb|	    q.put(source, dist[source])|\\
	\verb|	    while Q is not empty do|\\
	\verb|	        n| $\leftarrow$ \verb|Q.extract_min()|\\
	\verb|	        for each neighbor in v of n do|\\
	\verb|	            alt| $\leftarrow$ \verb|dist[n] + lenght(n, v)|\\
	\verb|	            if alt < dist[v] do|\\
	\verb|	                dist[v]| $\leftarrow$ \verb|alt|\\
	\verb|	                prev[v]| $\leftarrow$ \verb|n|\\
	\verb|	                Q.put(v, alt)|\\
	\verb|	    return dist, prev|\\
	%\end{BVerbatim}
	
	\caption{Pseudocodice dell'Algoritmo di Dijkstra (list of candidate)}
	\label{fig:dijkstraLoC}
\end{figure}

\subsection{One to all}
This implementation is useful to find \textbf{all the shortest paths} from a source node to each other graph's nodes. The starting node will save a dictionary where there is a key for each reached node and the respective value of distance.
It implements a \textit{priority queue} so the complexity of this implementation is $O((|N|+|A|)\log_2(|N|))$ where $N$ is the number of vertices and $A$ the number of edges. In the worst case, so where $A>>N$, the time complexity is $(|A|\log_2(|N|))$.

This implementation explores all the nodes reachable from the source; so it doesn't stop until the graph is totally explored.

\subsection{One to one}
This implementation focuses to find the shortest path between the node source and the target, using the classical implementation of Dijkstra's algorithm.\\
The difference with "One to all" is that this doesn't use a priority queue, but the algorithm will interrogate each not-visited node every loop, selecting the nearest node; this is very time consuming, in fact the complexity of this implementation is $O(|N^2|)$.


\subsection{List of candidate}
The last version of Dijkstra's algorithm is another implementation that uses a priority queue. The elements of this queue are inserted time to time by each new visited node, using the value of distance as priority value; so the queue's elements are the neighbors of the visited nodes, each time a node is visited it is removed from the queue. In this way the algorithm needs to interrogate only some nodes and not all the graph.\\
The list of candidate algorithm has the same \textit{worst-case complexity} of the \textit{One to all} algorithm: $O((|N|+|A|)\log_2(|N|))$.

\section{``A Star'' algorithm}
The A Star algorithm (or `A*') can be considered an extension of Dijkstra's algorithm, because it achieves better performance and accuracy by using heuristics\footnote{\url{https://en.wikipedia.org/wiki/Heuristic_(computer_science)}}. A*, to determinate how to extend its paths to the target, needs to minimizes this equation:

$$ f(n) = g(n) + h(n)$$
Where:
\begin{itemize}
	\item $n$ is the next path's node
	\item $g(n)$ is path's cost from the beginning to $n$
	\item $h(n)$ is the heuristic function
\end{itemize}
Heuristic, in this case, is the shortest distance from $n$ to the goal, so a \textit{straight-line} or better the \textbf{euclidean distance} to the target.
According with \footnote{\url{https://en.wikipedia.org/wiki/A*_search_algorithm}} the time complexity is related to $h$ and the number of nodes explored is exponential in the depth of the shortest path solution.
So the worst case is $O(|N|) \equiv O(b^d)$ where $b$ is the average number of successors per node and $d$ the depth of the solution.
\subsubsection*{Implementation's details}
At each iteration:
\begin{enumerate}
	\item The node with the lowest $f(n)$ is popped by the queue (implemented as a priority queue).
	\item Update the values of the neighbors and then add them to the queue.
	\item The algorithm repeat until the goal is reached.
\end{enumerate}
The Euclidean distance between two points is: $$\sqrt{(i_x - t_x)^2 + (i_y - t_y)^2}$$
where $i$ is a node of the graph and $t$ the target, $x$ and $y$ are latitude and longitude, converted to Cartesian coordinates.

To calculate the square root like this is very expensive, in term of time, so it is necessary to find a way for make this operation only one time per node (in this implementation the value of Euclidean distance is stored in an node's attribute).

\begin{figure}
	\verb|function DijkstraAlgorithm(source, target):|\\
	\verb|    score[source]| $\leftarrow 0$\\
	\verb|    create priorityQueue Q|\\
	\verb|    q.put(source, score[source])|\\
	\verb|    while Q is not empty do|\\
	\verb|        n| $\leftarrow$ \verb|Q.extract_min()|\\
	\verb|        for each neighbor v of n do|\\
	\verb|            if v not visited do|\\
	\verb|                tmpScore| $\leftarrow$ \verb|score[n] + lenght(v, n)|\\
	\verb|                if tmpScore < score[v] do|\\
	\verb|                    if euclidean[v] is None do|\\
	\verb|                        euclidean[v]| $\leftarrow$ \verb|calcEuclidean(v, target)|\\
	\verb|                score[v]| $\leftarrow$ \verb|tmpScore|\\
	\verb|                prev[v]| $\leftarrow$ \verb|n|\\
	\verb|                Q.put(v, tmpScore)|\\
	\verb|    return score, prev|\\
	\caption{Pseudocodice dell'Algoritmo A*}
	\label{fig:Astar}
\end{figure}



\section{Analysis of the results}
This paragraph shows the principal characteristics and results of each implementation.
\subsection{Performance comparison} 
In the figure \ref{fig:monoCriteriaOutput} are shown some results, from 15 different iteration, classified in three ``set" that groups different path's length.
\begin{figure}[H]
	\centering
	\includegraphics[width=\linewidth]{monoCriteriaOutput.png}
	\caption{Performance of the mono-criteria algorithms (generate with tkinter library)}
	\label{fig:monoCriteriaOutput}
\end{figure}
From the table it's possible to recognize that the first column, '\textit{one to all}', has a pretty much constant elaboration time (it comprehends the algorithm's work completion and the research in target node's attribute the distance from source). From the data of \textit{one to one} algorithm is easily to recognize that the implementation without a priority queue is too slow, especially in the longest paths. Comparing the total average times of the latest two algorithm is possible to see that the \textit{A Star}'s implementation is 3 times more faster than the \textit{List of candidate}'s implementation.
\textit{Dijkstra's List of candidate}, in average, is near to be five times more performing than the \textit{one to all} implementation.

\subsection{Node visited}

All the implementation are going to find the same path between nodes; in particular all the implementation (except for the \textit{A Star}'s algorithm) explore the same nodes, instead, the \textit{A*}, explores less number of nodes, this means that it makes less loops during the elaboration and research of the shortest path.

In the following pictures it is shown how, researching the shortest path, the algorithms visit nodes in a different way:\\
Dijkstra's algorithm (\textit{list of candidate}) makes a research more ``circling" around the source (big green point), instead the 'A Star', for its nature, is more direct and it reaches the target exploring an ``oval" between the starting nodes and the target. So it's easy to see and understand how A* is more efficient than the others implementation.\\
  
\begin{figure}[H]
	\textbf{\textit{Legend}:}
	\begin{itemize}
{\small 		\item \textbf{Blue}: Nodes of graphs.
		\item \textbf{Yellow}: Nodes visited.
		\item \textbf{Green}: Source node.
		\item \textbf{Black}: Target node.
		\item \textbf{Red line}: Path.}
	\end{itemize}
	\centering
%	\begin{minipage}[b]{\textwidth}
		\includegraphics[width=\textwidth]{img/mapOutput/2070-15426LoC.png}
		\label{fig:ListOfCandidate1}
%	\end{minipage}
%	\hfill
%	\begin{minipage}[b]{\textwidth}
		\includegraphics[width=\textwidth]{img/mapOutput/2070-15426A_Star.png}
		\label{fig:A_Start1}
%	\end{minipage}
	Source: 2070 $\to$ Target: 15426\\Map: Paris
\end{figure}
\begin{figure}[H]
	\centering
	\begin{minipage}[b]{\textwidth}
		\includegraphics[width=\textwidth]{img/mapOutput/2000-2689LoC.png}
		\label{fig:ListOfCandidate2}
	\end{minipage}
	\hfill
	\begin{minipage}[b]{\textwidth}
		\includegraphics[width=\textwidth]{img/mapOutput/2000-2689A_Star.png}
		\label{fig:A_Start2}
	\end{minipage}
	Source: 2000 $\to$ Target: 2689\\Map: Paris
\end{figure}
\begin{figure}[H]
	\centering
	\begin{minipage}[b]{\textwidth}
		\includegraphics[width=\textwidth]{img/mapOutput/1000-1510BerlinLoC.png}
		\label{fig:ListOfCandidate3}
	\end{minipage}
	\hfill
	\begin{minipage}[b]{\textwidth}
		\includegraphics[width=\textwidth]{img/mapOutput/1000-1510BerlinA_Star.png}
		\label{fig:A_Start3}
	\end{minipage}
	Source: 1000 $\to$ Target: 1510\\Map: Berlin
\end{figure}

\chapter{Bicriteria algorithms}

In this chapter the algorithms implemented to studying the case of a graph with arches having two different weights are explained.
Keeping in mind the mathematical explanation made in the introduction, it is possible to enunciate some definitions:

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\begin{definition}{Feasible solution}\\
	Let $x, y$ be two distinct feasible path from a source $s$ to a target $t$. It is said that $x$ \emph{dominates} $y$ if and only if $c^k(x) \leq c^k(y)$ $\forall$ $k \in \{1,2\}$.
\end{definition}

\theoremstyle{definition}
\begin{definition}{Convex hull}\\
	The \textbf{convex hull} of a set $X$ of feasible solutions is the smallest \textbf{convex set} that contains $X$. In this case is defined by the equation 
	\begin{equation}\label{eq:convex hull}
	\alpha*c^1 + (1-\alpha) c^2 = k
	\end{equation}
	\begin{center}
		where $k$ is constant and $\alpha \in \{0, 1\}$.\\
		and $c^1$ is the \textit{distance} and $c^2$ the \textit{danger}.
	\end{center}
\end{definition}

\begin{definition}{Pareto front}\\
	The \textbf{Pareto front} is a set of optimal solutions, so consisting of a set of not-dominated points (there's no other point that has better values at the same time for each point's criteria).
	\\A point can be part of the Pareto front without dominate any other points.
\end{definition}
{\small \textit{The figures \ref{fig:graphBiDi} and \ref{fig:graphLabSet} give a graphic representation of the definitions 2 and 3.}}

\section{Dijkstra applied to bicriteria}
According with the function \ref{eq:convex hull}, it is possible to say that ``bicriteria graph'' $G=(N,V,dist,dang)$, where \textit{dist} is $c^1$ and \textit{dang} is $c^2$, is reducible to $G=(N,V,\alpha*dist + (1-\alpha) dang)$  the problem can be addressed as the previous case, so using Dijkstra's algorithm (list of candidates) giving a value to $\alpha$. \\

It is easy to deduce that the more value of $\alpha$ approaches $0$ the more it is possible to find the safest paths. On the contrary the more $\alpha$ is approaching 1 the more shortest paths will be found.

\vspace{5mm}

The algorithm's implementation is similar to Dijkstra's list of candidate, but with the difference that this version needs in input, together with the source and the target, the value of $\alpha$; then, using \eqref{eq:convex hull}, the algorithm will choose the optimal path.

\begin{figure}[h]
	%	\begin{BVerbatim}
	\verb|function DijkstraAlgorithm(source, target, alpha):|\\
	\verb|	score[source]| $\leftarrow 0$\\
	\verb|	create priorityQueue Q|\\
	\verb|	Q.put(source, score[source])|\\
	\verb|	while Q is not empty do|\\
	\verb|	    n| $\leftarrow$ \verb|Q.extract_min()|\\
	\verb|	    for each neighbor v of n do|\\
	\verb|	        alt| $\leftarrow$ \verb|alpha*firstW(n, v) + (1 - alpha)*secondW(n, v)|\\
	\verb|	        alt| $\leftarrow$ \verb|alt + score[u]|\\
	\verb|	        if alt < score[v] do|\\
	\verb|	            score[v]| $\leftarrow$ \verb|alt|\\
	\verb|	            prev[v]| $\leftarrow$ \verb|n|\\
	\verb|	            Q.put(v, tmpScore)|\\
	\verb|	return score, prev|\\
	%	\end{BVerbatim}
	\caption{Pseudocodice dell'Algoritmo di Dijkstra con due criteri}
	\label{fig:Dijkstra Bicrit}
\end{figure}

\subsection{Application of Bicriteria Dijkstra}
To use the bicriteria Dijkstra's algorithm, it is needed to find a way to call the algorithm several times, with different values for $\alpha$

\subsubsection{Bicriteria Dijkstra iteration}
This is a very raw version, its operation is based on recalling the bicriteria Dijkstra's function, several time with different values for $\alpha$, increasing its value by a constant factor called ``\textbf{precision}".

The required elaboration time is related to the chosen precision, because it has to call the same function a lot of time and probably with the same result. So more precision means more results (\textit{feasible paths}), but with longer elaboration times.

\subsubsection{Bicriteria Dijkstra with binary research}
This version is an ``evolution" of the Bicriteria Dijkstra iteration, because it uses a \textit{binary research} algorithm. It is based on calling the function at least two time: with $\alpha = 0$ and $\alpha=1$, then, if the results are different, with $\alpha=0.5$, again, if the result is different with $\alpha=\alpha/2$, and so on and so on; until there's no more solution.

This version generally is more efficient and precise than the \textit{iteration} algorithm. The output on figure \ref{fig:dijkstraBiCriteriaSimple} shown that the \textit{Bicriteria Dijkstra iteration} with a precision of (e.g.) $0.2$ is pretty faster than the binary search; while, with a smallest value for precision (little value means more paths), the \textit{Bicriteria iteration} becomes slower but finds more results, but anyway it finds less results than binary search.

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{img/biCriteriaOutput.png}
	\caption{Output of the two version of Dijkstra's bicriteria algorithm.}
	\label{fig:dijkstraBiCriteriaSimple}
\end{figure}

\section{Label-setting algorithm}
In the paper was told that the algorithm using Dijkstra is not able to find all feasible solutions, but only those that make the \textit{Convex hull}; so this algorithm is useful for finding all the set of non-dominated solutions, hence the \textit{Pareto front}. Below a comparison of bicriteria Dijkstra and label-setting algorithm using two graphs for clarifying the concept.
\begin{figure}[H]
	\centering
	\begin{minipage}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth, trim= 0 0 15mm 14mm, clip]{img/graphDijkstraBicrit.png}
		\caption{Graph generated by \textit{Bicriteria Dijkstra with binary search}}
		\label{fig:graphBiDi}
	\end{minipage}
	\hfill
	\begin{minipage}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth, trim= 0 0 15mm 14mm, clip]{img/graphLabelsetting.png}
		\caption{Graph generated by \textit{Label-setting algorithm}}
		\label{fig:graphLabSet}
	\end{minipage}
\textit{{\tiny This example has been calculated using the map of Paris, starting from node 2000 to node 2689.}}
\end{figure}


In the graph \ref{fig:graphBiDi} are present only some point of the \textit{Convex hull} (red squares) found using bicriteria Dijkstra, while the second graph (\ref{fig:graphLabSet}) has much more points (yellow points) and, as it is possible to see, the label-setting algorithm has found also the points found by Bicriteria Dijkstra too (\textit{Convex hull}). The solutions found by label-setting algorithm are all feasible, hence it is more complete.

\subsection{Implementation}
Each node of the graph store a set of label with all the useful information ``inside" its; the structure of label is as follow:
$$(distance, danger, owner, predecessor, ownerIndex, predIndex)$$
The first two parameter are the costs of the path from the source, the third and four elements indicate the node that owns the label and from which node it comes, the fifth element is the label's position inside the label set of the owner node, the sixth indicate the position of parent's label inside its label set (used for backtracking).
As always happens the algorithm uses a priority queue where labels are stored and then chosen in function of the distance's value. The algorithm works in this way:

\begin{enumerate}[label=\roman*.]
	\item Create first label $(0,\ 0,\ s,\ null,\ 0,\ null)$ and put in the priority queue ($s$ represent the starting point).
	\item If the queue is empty perform step ({6}) otherwise get the label with smallest distance's value from the queue and calculate the label for all its owner's neighbors.
	\item Check if the calculated label is or isn't a non-dominated label. There's can be three different solution: 
	\begin{enumerate}
		\item The calculated label is dominated, so the algorithm will discards it.
		\item The calculated label dominate other labels, so those labels can be removed.
		\item The calculated label doesn't dominate any other label, but it isn't dominated at all, so the algorithm will keep it.
	\end{enumerate}
	\item If the calculated label is feasible is put in the queue, using the distance as a criteria for its priority.
	\item Return to step ({2}).
	\item End.
\end{enumerate}

\begin{figure}[h]
	%\begin{verbatim}
	\verb|function DijkstraAlgorithm(source, target):|\\
	\verb|    originLabel| $\leftarrow$ \verb|(0, 0, source, Null, 0, Null)|\\
	\verb|    source.add(originLabel)|\\
	\verb|    create priorityQueue Q|\\
	\verb|    Q.put(orginLabel, priority())|\\
	\verb|    while Q is not empty do|\\
	\verb|        actualLabel| $\leftarrow$ \verb|Q.extract_min()|\\
	\verb|        owner| $\leftarrow$ \verb|actualLabel[2]|\\
	\verb|        for each neighbor v of owner do|\\
	\verb|            firstW| $\leftarrow$ \verb|weightOne(owner, v) + actualLabl[0]|\\
	\verb|            secondW| $\leftarrow$ \verb|weightTwo(owner, v) + actualLabel[1]|\\
	\verb|            vIndex| $\leftarrow$ \verb|v.labelIndex()|\\
	\verb|            predIndex| $\leftarrow$ \verb|owner.labelIndex()|\\
	\verb|            label| $\leftarrow$ \verb|(firstW, secondW, v, owner, vIndex, predIndex)|\\
	\verb|            if label is not dominated by v.labels() do			|	\\
	\verb|                v.labelsAdd(label)    //rimuove i label dominati|\\
	\verb|                if v is not target do|\\
	\verb|                    Q.put(label, priority())|\\
	%\end{verbatim}
	\caption{Pseudocodice dell'Algoritmo Label-setting}
	\label{fig:LabelSetting}
\end{figure}

\subsubsection*{Example:}
Is possible to study the graph in figure \ref{fig:graphExample} starting from node 1, so this node will have the label $(0,\ 0,\ 1,\ null,\ 0,\ null)$ in its set. Then creating labels for its neighbors (2 and 3): $(3,\ 4,\ 2,\ 1,\ 0,\ 0)$ and $(5,\ 3,\ 3,\ 1,\ 0,\ 0)$ and put both in the queue. Extracting label owned by node 2 and do the same thing as before and so on, until the target node is reached. At any new label should be studied if it is feasible or not before putting it in the queue.

\subsection{Lower bound improvement}
\begin{center}
	\noindent\rule{8cm}{0.1pt}
\end{center}
{\small The original thought was to make a preprocessing phase that would have retraced the path backwards and, in this way, calculates the distance (and danger) from the target to each visited node, to know in advice which would have been the lowest value for each of them. But i noticed that this thought doesn't work with graphs with edges between nodes oriented in more directions with different values for each direction. So I implemented a different solution, below there's the explanation.}
\begin{center}
	\noindent\rule{8cm}{0.1pt}
\end{center}
This algorithm use a technique that try to improve the speed. This technique consist in a \textit{preprocessing phase}, where, with Bicriteria Dijkstra algorithm, is possible to calculate the safest and the shortest path from the source to the target node and, for each visited node, store information about the distance and the danger of the visited node from so far. To calculate those values it uses Bicriteria Dijkstra with $\alpha = 1$ to find the optimal values for distance, and $\alpha = 0$ for the danger.

How it can be useful?
\\
Is known that the research of the shortest and the safest path will generate the best value for distance and danger for each visited node. So, once calculated the shortest path and the safest, during the elaboration of label-setting algorithm, will be known the following information: the total value of the full path's distance (and danger), \textit{preprocessing-visited node}'s best value of distance (and danger), the value of distance (and danger) calculated during the running of the algorithm. 

Is possible to do this evaluation:
\begin{itemize}
	\item[-] $pd =$ best path's distance.
	\item[-] $nd =$ best node's distance.
	\item[-] $ad =$ actual node's distance, calculated at that exact moment by the algorithm.
	\item[-] $td =$ temporary value of distance.
	\item[-] $res =$ future value of distance for that specific node.
\end{itemize}
$$ td = pd - nd$$
$$res = td + ad$$
Doing the same thing with danger is possible to find the projection of the final label of that specific node and valuate if it is dominated or not.
\subsection{Complexity}
The worst-case example is represented in the graph below, where there is the remote possibility to find always feasible node for each iteration, that is when one weight is zero and the other is bigger than the last one, for each arc:

\begin{figure}[H]
	\centering
	\includegraphics[width=\linewidth]{img/labelSettingComplexity.png}
	\caption{Worst-case label-setting algorithm's example}
	\label{fig:worstCaseLabelSettin}
\end{figure}
Is now possible to say that the complexity is $O(2^{n-1})$ where $n$ is the number of nodes. 


\section{Analysis of results}
Now it is possible to analyze the results. In the figure below (\ref{fig:worstCaseLabelSetting2}) is possible to see an extract generated by the execution of the three algorithms explained before.
Is possible to note that the nodes used for the execution are the same used in monocriteria's execution (randomly generated), in this way is possible to make some comparison, but is obvious that the monocriteria is faster than bicriteria. 
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6, trim=0.2mm 0 0 0, clip]{img/biCriteriaExcelOutput1.png}
	\label{fig:worstCaseLabelSetting1}
	
	\vspace{3mm}
	
	\centering
	\includegraphics[width=\textwidth, trim=0.2mm 0 0 0.1mm, clip]{img/biCriteriaExcelOutput2.png}
	\caption{Output of all relevant algorithms in terms of number of solution and time spent (excel table generated with \textit{xlsxwriter} library).}
	\label{fig:worstCaseLabelSetting2}
	\textit{\begin{center}
			{\small The tables have been slightly modified to make reading easier, but the values are original}
	\end{center}}
\end{figure}

\section{Bidirectional Bi-criteria Algorithm}
\subsection{Implementation}
\begin{figure}[H]
	%\begin{verbatim}
	\verb|function BidirectionAlgorithm(source, target):|\\
	\verb|    create priorityQueue Q[f]   //forward|\\
	\verb|    create priorityQueue Q[b]   //backward|\\
	\verb|    create list L|$_{result}$\\
	\verb|    originLabel| $\leftarrow$ \verb|(0, 0, source, Null, 0, Null)|\\
	\verb|    source.add(originLabel)|\\
	\verb|    Q[f].put(originLabel)|\\
	\verb|    targetLabel| $\leftarrow$ \verb|(0, 0, source, Null, 0, Null)|\\
	\verb|    source.add(targetLabel)|\\
	\verb|    Q[b].put(targetLabel)|\\
	\verb|    while [min|$_i$\verb|(Q[f]) + min|$_i$\verb|(Q[b])]|\\\verb|                        is not dominated by any| R$\in L_{results}$ \verb|do|\\
	\verb|        d| $\leftarrow$ \verb|getDirection()    //forward o backward|\\
	\verb|        actualLabel| $\leftarrow$ \verb|Q[d].extract_min()|\\
	\verb|        owner| $\leftarrow$ \verb|actualLabel[2]|\\
	\verb|        for each neighbor v of owner do|\\
	\verb|            firstW| $\leftarrow$ \verb|weightOne(owner, v) + actualLabl[0]|\\
	\verb|            secondW| $\leftarrow$ \verb|weightTwo(owner, v) + actualLabel[1]|\\
	\verb|            vIndex| $\leftarrow$ \verb|v.labelIndex()|\\
	\verb|            predIndex| $\leftarrow$ \verb|owner.labelIndex()|\\
	\verb|            label| $\leftarrow$ \verb|(firstW, secondW, v, owner, vIndex, predIndex)|\\
	\verb|            if label is not dominated by v.labels(d) do			|	\\
	\verb|                v.labelsAdd(label, d)   //rimuove i label dominati|\\
	\verb|                Q[d].put(label)|\\
	\verb|                if v.labels(!d) is not empty do   //!d = direzione opposta|\\
	\verb|                    result| $\leftarrow$ \verb|combine(label, v.labels(!d))|\\
	\verb|                    L|$_{results}$\verb|.addResults(results)|
	%\end{verbatim}
	\caption{Pseudocodice dell'Algoritmo bidirezionale}
	\label{fig:bidirectional}
\end{figure}
\subsubsection{Particular Stop Condition Case}

\subsection{Performance comparison}
Excluding bicriteria Dijkstra's algorithm, which is advantageous only with nodes very far from each other, at the expense of the number of solution; the other two label-setting implementations results to be very similar; in fact \textit{lower bound improvement} algorithm seems to be advantageous only with nodes in a medium-large distance from each other, in others case is pretty in line with the normal label setting algorithm. It is possible also to see that the \textit{lower bound improvement} makes less loops than the other algorithm, but this difference becomes increasingly irrelevant with the increasing distance between the nodes.

\begin{table}
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.6, trim=0.2mm 0 0 0, clip]{biCriteriaExcelOutput1v2.png}
		\label{fig:worstCaseLabelSetting1}
		
		\vspace{3mm}
		
		\centering
		\includegraphics[width=\textwidth, trim=0.2mm 0 0 0.1mm, clip]{biCriteriaExcelOutput2v2.png}
		
		\label{fig:worstCaseLabelSetting2}
	\end{figure}
	\caption{Risultati degli algoritmi applicabili a grafi orientati (I fogli excel sono stati generati per comodità tramite la libreria \textit{xlsxwriter}).}
	\label{tab:BidirectionalOriented}
\end{table}

\begin{table}[H]
	\begin{tabular}{ |p{2cm}||p{2cm}|p{3cm}|p{2cm}|p{3cm}|  }
		\hline
		Nodo di arrivo & Soluzioni trovate & Tempo impiegato (sec) & Soluzioni trovate & Tempo impiegato (sec) \\
		\hline
		& \multicolumn{2}{|c|}{Dijkstra Iter. \textbf{prec.} = 0.05} &
		\multicolumn{2}{|c|}{Dijkstra binary search} \\
		\hline
		
		10 & 5 & 10.06989 & 5 & 6.02213\\
		100 & 23 & 32.07635  & 12 & 11.89208\\
		500 & 84 & 96.60857 & 23 & 82.71155\\
		700 & 123 & 210.80490 & 27 & 23.74903\\
		5000 & 593 & 664.78488 & 46 & 23.74327\\	
		\hline
		
	\end{tabular}
	\\
	\\
	
	\begin{tabular}{ |p{2cm}||p{2cm}|p{3cm}|p{2cm}|p{3cm}|  }
		\hline
		Nodo di arrivo & Soluzioni trovate & Tempo impiegato (sec) & Soluzioni trovate & Tempo impiegato (sec) \\
		\hline
		&\multicolumn{2}{|c|}{Label-setting} &  \multicolumn{2}{|c|}{bidirectional algorithm} \\
		\hline
		10 & 10 & 0.00040 & 4 & 0.00019 \\
		100  & 116 & 1.05214 & 66 & 0.12038 \\
		300  & 663 & 98.73498 & 242 & 2.4432 \\
		500 & 1867 & 925.68206 & 193 & 22.14023 \\
		700 & 3278 & 4795.59632 & 429 & 141.73064\\
		
		\hline
		
	\end{tabular}
	\\
	\\
	
	\begin{tabular}{ |p{2cm}||p{2cm}|p{2.5cm}|p{3cm}|p{2.5cm}|  }
		\hline
		Nodo di arrivo & Soluzioni trovate & \multicolumn{3}{|c|}{Tempo impiegato (sec)} \\
		\hline
		& & Dijkstra preprocessing &  lower bound improvement & lower bound reversed \\
		\hline
		10 & 10 & 0.00011 & 0.00050 & 0.00055 \\
		100  & 116 & 0.00095 & 0.60899 & 0.69986 \\
		300  & 663 & 0.00402 & 74.03828 & 87.22029 \\
		500 & 1867 & 0.00486 & 930.81834 & 927.77959 \\
		700 & 3278 & 0.05327& 4887.63521 & 4931.99105\\
		
		\hline
		
	\end{tabular}
	\caption{Risultati degli algoritmi bicriteria in un grafo non orientato con 200000 nodi connessi a cascata tramite archi dai valori casuali (tutti i cammini partono da 0 e i nodi sono collegati ad altri 4 nodi, due antecedenti e due precedenti)}
	\label{tab:BidirectionalNotOriented}
\end{table}

\subsection{Node visited}
Despite the lower bound algorithm does less loops, the visited nodes are less but almost the same than the label-setting algorithm, so only one image is shown for both algorithms, since the difference is almost imperceptible.
\begin{figure}[H]
	\centering
	%	\begin{minipage}[b]{\textwidth}
	\includegraphics[width=\textwidth]{immaginiTest/Paris2070-15426Bicriteria.png}
	\label{fig:BicriteriaParis}
	%	\end{minipage}
	%	\hfil
	Source: 2070 $\to$ Target: 15426\\Map: Paris
	\caption{Label-setting algorithm (Paris oriented map).}
\end{figure}
\begin{figure}[H]
	\centering
	\begin{minipage}[b]{\textwidth}
		\includegraphics[width=\textwidth]{immaginiTest/1000-1510BerlinBicriteria.png}
		\label{fig:BicriteriaBerlin}
	\end{minipage}
	Source: 1000 $\to$ Target: 1510\\Map: Berlino
	\caption{Label-setting algorithm (Berlin oriented map).}
\end{figure}
\begin{figure}[H]
	\centering
	\begin{minipage}[b]{\textwidth}
		\includegraphics[width=\textwidth]{immaginiTest/BolognaBiC1298-23289Big.png}
		\label{fig:BolognaBiC1298-23289Big}
	\end{minipage}
	Source: 1298 $\to$ Target: 23289\\Map: Bologna (Province)
	\hfill
	\begin{minipage}[b]{\textwidth}
		\includegraphics[width=\textwidth]{immaginiTest/BolognaBiC1298-23289.png}
		\label{fig:BolognaBiC1298-23289}
	\end{minipage}
	Source: 1298 $\to$ Target: 23289\\Map: Bologna (Province)\\ detail
	\caption{Label-setting algorithm Bologna (not-oriented map).}
\end{figure}
\begin{figure}[H]
	\centering
	\begin{minipage}[b]{\textwidth}
		\includegraphics[width=\textwidth]{immaginiTest/BolognaBidir1298-23289Big.png}
		\label{fig:BolognaBidir1298-23289Big}
	\end{minipage}
	Source: 1298 $\to$ Target: 23289\\Map: Bologna (Province).
	\hfill
	\begin{minipage}[b]{\textwidth}
		\includegraphics[width=\textwidth]{immaginiTest/BolognaBidir1298-23289.png}
		\label{fig:BolognaBidir1298-23289}
	\end{minipage}
	Source: 1298 $\to$ Target: 23289\\Map: Bologna (Province)\\ detail
	\caption{Bidirectional algorithm Bologna (not-oriented map).}
\end{figure}

\chapter{Implementation details}
This chapter explains some of the main implementation choices made during the development of the project.
\section{Python}
I've decide to choose this language (also because recommended by the professor) because it is a modern and constantly growing language, used in many IT fields. it is very versatile and is incredibly supported by the community, so is possible to find different guides, libraries and tips on the internet.
\subsection{Binary queue}
Theoretically the best implementation of Dijkstra's algorithm is with a \textit{Fibonacci heap} ($O(|N|\log_2|N|+|A|)$), but according with \footnote{\url{https://dnshane.wordpress.com/2017/02/14/benchmarking-python-heaps/}} and after some verification I noticed that using a priority queue, implemented thanks to the \textit{heapq} included in the python standard library, was faster in the extractions and insertions; this because it uses C implementations.

\section{Nodes as objects}
I decided to use the object paradigm for the nodes of the graph, because, due to the nature of the study, it was more convenient to add and remove attributes or functions to the object ``node" and simplified my work. Also because it generates a clearer and more readable code.\\
This implementation use the following attribute in the "object node":
\begin{itemize}
	\item[$-$] \textbf{index}: Indicates the index of the node.
	\item[$-$] \textbf{longitude \& latitude}.
	\item[$-$] \textbf{x \& y}: Cartesian coordinates of longitude and latitude.
	\item[$-$] \textbf{neighbors}: A list with all information about the neighbors (distance and node).
	\item[$-$] \textbf{visited}: Indicates if the node is visited or not.
	\item[$-$] \textbf{predecessor}: the node predecessor this node.
	\item[$-$] \textbf{minWeight}: the total weight from the source node.
	\item[$-$] \textbf{shortestPaths}: stores information about all the nodes from the source to this node. (Used only in \textit{one to all} implementation)
	\item[$-$] \textbf{euclidean}: stores the euclidean distance from this node to target. (Used only in \textit{A*} implementation)
	\item[$-$] \textbf{distance \& danger}: store the values from the source so far. (Used only in bicriteria algorithm).
	\item[$-$] \textbf{labelList}: A list of all label of this node. (Used only in \textit{label-setting} algorithm).
\end{itemize}
\section{Pandas \& Matplotlib}
For parsing the ``.CSV" files I decided to use \textit{Pandas} library. It is not the only library that can interact with CSV files, but it is very recommended for deal with a large amount of data.
Pandas is an open-source Python library that provides high performance data analysis tools and easy to use data structures. It is also a key part of the Anaconda distribution and works extremely well in Jupyter notebooks to share data, code, analysis results, visualizations, and narrative text. For more information about \textit{Panda} read this article \footnote{\url{https://realpython.com/python-csv/}}.
\vspace{5mm}

Matplotlib is another open-source Python library for 2D graphs based on the famous math library NumPy. Matplotlib has a lot of documentation on the web and it pretty simple to make graphs (I used this library to make all images that represents cities and paths).
Provides object-oriented APIs that allow you to insert graphics into applications using the generic GUI toolkit, so is possible to re-use the graphs for other implementations \footnote{\url{https://matplotlib.org/}}.
\section{Testing}
I realized two files for \textit{testing in the small} the code, using simple terminal output; one is for the monocriteria algorithms and the other is for the bicriterias. This two files have a lot of commented code, used for showing different information, like the number of results, backtracking, time, graphs and so on. For a global test and for a good visualization of data I used matplotlib to generate tables (like the one in figure \ref{fig:monoCriteriaOutput}) and graphs, but also the library \textit{xlsxwriter} to make a rapid visualization table on a spreadsheet (\ref{fig:worstCaseLabelSetting2}).

\chapter{Personal considerations}
I have developed this project during my Erasmus period, I have hocked spirit and time in order to best meet the requested objective. It was the first time that I did a study of this kind.

\section{Other possible solution}
\subsection*{Genetic algorithm}
\textit{The following is a personal and unimplemented possible solution, maybe interesting to see and with a possible application or study for the future.
It has to be taken only like a conjecture made for pure passion and self-interest.}
\vspace{10mm}\\
This conjecture will try to find a solution in a not-polynomial time.

The \textbf{first population}, generated with random genes, will travel, starting from the source node, trough the graph guided by the genes. Not all genotype will get to the target, but the ones which arrived at the destination have accumulated a value for the distance and for the danger.
The solution that are arrived to the target must be stored, but, unlike what has been done so far, the dominated solutions don't have to be removed. In this way it is possible to avoid \textit{local optima} (a set of solutions that seems to be optimal only within a set of neighbors), it will be the task of the \textit{\textbf{fitness functions}} and the \textit{selection} to "clean" solutions. 
Therefore it is possible to implement two \textit{fitness functions}, one for valuate the distance and one for the danger, associating to all the remaining solution some parameters, based on the results of the fitness and the travel time.
Anyway it is not granted that from two good solutions a third one is good too and neither that from two solutions with a certain fitness values it is generated a third one with the same fitness values. To solve these problems generally is used some criteria to chose a set from all the solution and use that for the \textbf{crossover phase}.
For example it is often used a selection that attribute a ``probability of extraction", based on the fitness function, to some result and then select some of them considering the probability.
For time reasons is preferred to chose two or more solution based only on the best fitness, paying attention to chose the shortest and the safest paths.
Using methods of \textbf{\textit{crossovers}} and \textbf{\textit{mutation}} (random changes inside the genotype, useful to improve the fitness function or to improve the research; usually a mutation has a probability value with which it can happen) a new population (generation 2) is generated; now is possible to restart the algorithm with the new population. 

Going over with this method, after some iteration, is possible to get a certain number of optimal solutions, which will compose a sort of \textit{Pareto front}.\\
For terminate the process is possible to put some condition; for example:
\begin{itemize}
	\item Reached a certain number of solution that satisfied a minimum criteria (e.g. a set of solution reach a certain fitness value).
	\item Reached a certain number of generations (useful to limit the time consuming).
	\item  Solution too similar for each iteration.
\end{itemize}


for further information see the bibliography.

\section{Other possible application}
It would be interesting to see also the same algorithm used to study a path that uses, instead of danger, a factor of pollution or energy consumption, to find a set of ``eco-paths''.


\section{Difficulties encountered}
The main difficulties encountered were, not so much the implementations, but the optimizations of the algorithms to obtain better performance. As well the study behind the developing of the label-setting algorithm, in particular to implement it in order to obtain an efficient backtracking. 


\section{All not-standard python's libraries used:}
\begin{itemize}
	\item[$-$] pandas
	\item[$-$] matplotlib
	\item[$-$] tkinter
	\item[$-$] xlsxwriter
\end{itemize}
\nocite{*}

\section{Computer info}
All tests were performed on a PC with the following characteristics:\\
\textbf{-- CPU\\}
product:\hspace{17mm}        Intel(R) Core(TM) i5-4300U CPU @ 1.90GHz - 2.90GHz\\
Architecture:\hspace{9mm}   x86\_64\\
CPU op-mode(s):\hspace{2mm}  32-bit, 64-bit\\
Byte Order:\hspace{11mm}     Little Endian\\
CPU(s):\hspace{18mm}         4\\


\bibliographystyle{abbrv}
\bibliography{template}

\end{document}
